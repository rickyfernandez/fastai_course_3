{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.datasets import untar_data, URLs\n",
    "\n",
    "from exp.data import\\\n",
    "    ItemList,\\\n",
    "    grandparent_splitter,\\\n",
    "    SplitData,\\\n",
    "    random_splitter,\\\n",
    "    LabeledData,\\\n",
    "    label_by_func,\\\n",
    "    get_dls,\\\n",
    "    DataBunch\n",
    "\n",
    "from exp.callbacks import\\\n",
    "    ProgressCallback,\\\n",
    "    AvgStatsCallback\n",
    "\n",
    "from exp.utils import accuracy\n",
    "\n",
    "from exp.utils import get_files\n",
    "from exp.learner import Learner\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "import PIL, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training'),\n",
       " PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create List Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageList(ItemList):\n",
    "    @classmethod\n",
    "    def from_files(cls, path, extensions='.png', recurse=True, include=None, **kwargs):\n",
    "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
    "    def get(self, fn):\n",
    "        return PIL.Image.open(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = ImageList.from_files(path, include=[\"training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageList (60000 items)\n",
       "[PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/36655.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/32433.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/28319.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/4968.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/23502.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/37211.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/51194.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/374.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/27016.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/5492.png')...]\n",
       "Path: /Users/ricardofernandez/.fastai/data/mnist_png"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABB0lEQVR4nNXQvUoDURCG4W+DC0KwiGDAKiGFkEq8ARVMoUjwHwsR0ngFNpJOKwn2dv5cRRAsxEYhWKSxENItimkUJIj6DmsRcd1dT2HpNIczz4Ez30j/qbyfl9zErDdXvm3u9lLv/EoABtBaTGEDvtCelxO2bwCn69VLjGbC3o1OLS8V7zD2Yjb2aOHblCS/YRYGxRhuwNO8JO0AdhazUhe2JU0vBUB9tN8d6B9Dw1J3s7BS9kOpchEfZ/w7BZ1aJpEjf3X/EdqLWWj1qButb3VQmSN5NwsPqfVIkrbgdeZ3Uq4N5w7LHsB11oEls96Iw3QMJy5bM6jGW1HggqRJF7YOJeeXf61PsJp5+23wRSQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x1A251A5B10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = imgs[1]; img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SplitData.split_by_func(imgs, partial(random_splitter, p_valid=0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: ImageList (51129 items)\n",
       "[PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/36655.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/32433.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/28319.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/4968.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/23502.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/37211.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/51194.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/374.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/27016.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/5492.png')...]\n",
       "Path: /Users/ricardofernandez/.fastai/data/mnist_png\n",
       "\n",
       "Valid: ImageList (8871 items)\n",
       "[PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/19113.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/52462.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/4983.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/33249.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/25371.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/9041.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/40270.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/15517.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/43751.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/18755.png')...]\n",
       "Path: /Users/ricardofernandez/.fastai/data/mnist_png"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_label(fn):\n",
    "    return int(fn.parent.name)\n",
    "mnist_label(imgs.items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = label_by_func(sd, mnist_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: LabeledData\n",
       "x: ImageList (51129 items)\n",
       "[PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/36655.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/32433.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/28319.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/4968.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/23502.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/37211.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/51194.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/374.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/27016.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/5492.png')...]\n",
       "Path: /Users/ricardofernandez/.fastai/data/mnist_png\n",
       "y: ItemList (51129 items)\n",
       "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9...]\n",
       "Path: /Users/ricardofernandez/.fastai/data/mnist_png\n",
       "\n",
       "\n",
       "Valid: LabeledData\n",
       "x: ImageList (8871 items)\n",
       "[PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/19113.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/52462.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/4983.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/33249.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/25371.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/9041.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/40270.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/15517.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/43751.png'), PosixPath('/Users/ricardofernandez/.fastai/data/mnist_png/training/9/18755.png')...]\n",
       "Path: /Users/ricardofernandez/.fastai/data/mnist_png\n",
       "y: ItemList (8871 items)\n",
       "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9...]\n",
       "Path: /Users/ricardofernandez/.fastai/data/mnist_png\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemList (51129 items)\n",
       "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9...]\n",
       "Path: /Users/ricardofernandez/.fastai/data/mnist_png"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAACHElEQVR4nO3Zz4tNcRjH8ZfJghA1C5ndLCUbykJ2SmKhyULJxmyUsNOUUiT+BFlIkZUNsbFRLBQ12agrG1mRH4uRRlMYFvdHZ+aMzveeO/WknnfdxTn3nKd3nz7d8z3fS5IkSZIkSZIkSRLMmhHu3QBb4SG2QwdX4F7pkLERBFaFFAgXaFvCKVyAXfCn9v0EPpcMCk8gBcIFhizhTpyBY9g4GFAv4XWcK5kYnkAKlHdgHN5iS33AfVyGHbgJP7Eb3jWMDU8gBcIF1hZfeYdlBZyFI/ANC/Aax+Ew9pIl/A8EGjuwHmZwCBb7p19hP8wvuXocV+Er7pYIhCeQAuECjSXcRndts0hl6fPU8v7NwHk8gbOlAuEJpEBjBxao/P4M2IwDg6ODOEH3YXUU5nAJPjbMD08gBcIFGks4Cev6R1/wA6Z7n3+9mn3X628T4QmkQLhA2bvhB70t0Xrb6iWcpbtcm69dvALhCaRAWQdu4SQrPRbHaqcn4FOpQHgCKRAuULY/MI2XcKp/poPHcJvKD9Fz3c2CcsITSIFR/rYDv6l0YAqPhro/PIEUCBco36gs4v3Qd4QnkAKjdOD0kqNn8GboIeEJpEC4wCglvEhlWT4Hv4YeEp5ACoQLtC3hPmyisol+o92g8ARSoG0HJlW2L0chPIEUCBdYnWX5A7xod2t4AinQtgMdvYX4Hrim+x9JC8ITSIFwgSRJknD+Au/ETT+U80B2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x1A2521B7D0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.train[0][0].resize((128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform: _order=0\n",
    "    \n",
    "class ResizeFixed(Transform):\n",
    "    _order=10\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, int): size=(size, size)\n",
    "        self.size = size\n",
    "        \n",
    "    def __call__(self, item): return item.resize(self.size, PIL.Image.BILINEAR)\n",
    "    \n",
    "def to_byte_tensor(item):\n",
    "    res = torch.ByteTensor(torch.ByteStorage.from_buffer(item.tobytes()))\n",
    "    w,h = item.size\n",
    "    return res.view(h, w, -1).permute(2, 0, 1)\n",
    "to_byte_tensor._order=20\n",
    "\n",
    "def to_float_tensor(item): return item.float().div_(255.)\n",
    "to_float_tensor._order=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [to_byte_tensor, to_float_tensor]\n",
    "\n",
    "image_list = ImageList.from_files(path, transforms=transforms)\n",
    "split_data = SplitData.split_by_func(image_list, partial(random_splitter, p_valid=0.15))\n",
    "label_data = label_by_func(split_data, mnist_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(im, figsize=(3,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(im.view(28, 28))#permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(label_data.train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(label_data.train, label_data.valid, bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 28, 28]), torch.Size([8]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 21, 21])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = nn.Conv2d(1, 8, kernel_size=8)\n",
    "out = con(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 10, 10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2, stride=2)\n",
    "out = pool(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 10, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re = nn.ReLU(True)\n",
    "out = re(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 3, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Net()\n",
    "m.localization(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.affine_grid??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 28, 28])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(32, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 28, 28, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = F.affine_grid(torch.randn(8, 2, 3), x.size())\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 28, 28])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.grid_sample(x, grid).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.621313</td>\n",
       "      <td>0.101767</td>\n",
       "      <td>2.397765</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-07948d3b31f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/repos/fastai_course_3/course_2/exp/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, cbs, reset_opt)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_begin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"begin_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/repos/fastai_course_3/course_2/exp/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after_cancel_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/repos/fastai_course_3/course_2/exp/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, xb, yb)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                           \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mamsgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amsgrad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# State initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [ProgressCallback,\n",
    "             partial(AvgStatsCallback, accuracy)]\n",
    "\n",
    "model = Net()\n",
    "loss = F.cross_entropy\n",
    "\n",
    "learn = Learner(model, data, loss, lr=0.4, cb_funcs=callbacks, opt_func=Adam)\n",
    "learn.fit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
